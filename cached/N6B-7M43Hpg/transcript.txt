i'm kind of interested obsessively in one thing and i'll try any technique that helps me answer that one thing and the one thing i'm interested in understanding is the nature of human choice behavior and i think it's a central puzzle why does human choice behavior work the way it does that has obsessed people really since i think the 19 mid to late 1960s before 1960 it was so clear what people did when they made choices was optimize each of us was optimizing a different function called our utility function and nobody wanted to second guess what utility function you used but everything you did was clear transparent optimization in the late 1960s it became clear that that wasn't a good description a lot of you know this and that people seem to be very intransitive in some of their choices they made choices which were logically inconsistent which we could prove seem not to optimize any underlying function and this gave rise ultimately to behavioral economics and and technically as economists we'd say that people are irrational this is endlessly confusing irrationality to an economist is a purely technical concept implying typically a violation of transitivity and so to me as a biologist this is a really puzzling puzzling idea why is it that biola evolved biological organisms seem to be inefficient in the way they make choices they fail to optimize that's a sort of core idea and as a psychologist which is another one of the hats i wear the way we tend to think of this problem was really an idea gifted us by i think mostly by amis taversky on your right but by danny kahneman and emma stoverski in their famous work on prospect theory and alice's idea which is really clever is that the reason people are so intransitive and crazy and busted in their choice behavior is that inside their brains live several different agents each one of these individual agents is a perfect optimizer who knows exactly how to achieve what he or she wants but because our brains are filled with these multiple agents and they fight for control of our behavior we wind up producing these discontinuities as the control shifts from one agent to another and these discontinuities make us inefficient sometimes tragically so now i mean i have to say that this is a beautiful explanation it's one that has really really deep historical roots this is really the idea that plato put forward in the times he said that we're like a chariot with that has a charioteer and two horses one who is rational i'm paraphrasing a little bit and one who is emotional and that the charioteer's job is to sort of steer these two things to a good end this is really the idea i think at the center of freud the id and the ego and the super eager or similar kind of three busted critters fighting with each other and um danny and amis i really think what they really did was they turned this into an almost biological idea danny would say that's not true but i do think that that's kind of the core notion the idea is that somewhere in our brain is maybe a financial decision maker who's efficient and rational and it lives at some physical location somewhere else in our brain is a different object that might be responsible for self-control it's what tells us to eat the salad and not the chocolate cake and it's when that little guy loses control that we make bad decisions like gaining weight or choosing to consume drugs or becoming addicted to heroin and oh sorry and that like choosing to be impulsive and choosing to get addicted to heroin now i have to say as a biologist this is a really strange idea and i mean i hope all of you can imagine you know we have all this great biological data about how animals choose in the wild animals you know moose we can specify the objective function a moose has to meet when he's living out in the wild how much salt he has to get how many calories he has to get how he's going to achieve these goals and they achieve it to you know five decimal places and the story is that every animal that we've looked at whether it's foraging theory the marginal value theorem does a pretty darn good job of meeting the biological constraints that they face except goes the story humans who although we have taken over the whole darn planet are tragically busted bad decision makers the worst animals that ever arose in history and i mean to me even as a young assistant professor it's a really hard story to live with and so i want to propose an alternative view and one that's kind of a mix of the original idea of expected utility theory from people like my hero john von neumann who was sort of the guardian angel of that irrational slide up in the top corner that but combine it with biology and combine it with what we know so here's another story instead of there being 10 choosers inside your brain there really is one chooser inside your brain there's a there has to be one chooser if we're going to be efficient we have to be able to choose between apples and oranges and that chooser has to have access to a ton of data that chooser does weird stuff that chooser is sometimes impulsive and intransitive but as a biologist i have to believe that that chooser builds a representation of the value of the options in the outside world parks them in his or her brain chooses the thing that has the highest value to him that's the sort of core idea of expected utility is maximizing something but the thing he's maximizing just is irrational it's weird it has weird features that we don't understand yet now when we first said that oh so i'm just going to say that here so when we first said that 25 or 30 years ago i think the general reaction was are you out of your mind have you not been paying attention do you not read the literature what's wrong with you guys and what i'm going to do is i'm going to explain to you something that's taken me 30 years to figure out which is that the thing that makes us kooky in our choices is kind of one thing and that's the idea that there is limited precision in the nervous system and we have to deal with the fact that we have a limited precision and coding system that's our fundamental weakness and our fundamental strength and that all the strange behaviors we see come from an effort to optimize the efficiency of our choices in the face of the fact that we have limited precision i'm going to really beat on this idea and try and convince you of it but before i do that i have to kind of convince you that there aren't a whole bunch of little people in your head and this is so pervasive an idea in our culture it has such deep roots and i would say that if i went to you know the society for neuroscience and said raise your hand are there multiple little people in your head 90 of people would raise their hands and say in some sense yes that's true but if i went to the society for neuroeconomics meeting and asked that question maybe two people would raise their hand and so this is huge disconnect where all the people who study this for a living have kind of decided that wasn't true but the people who are kind of at a larger distance haven't yet agreed that the people who study for living are right so i'm not going to show you the 500 good experiments on this i'm going to show you sort of three two from my lab and this really represents work that my lab did from kind of 2005 6 to 2015-18 and so i'm going to tell you a couple of stories the first story i'm going to tell you is joe cable's story he was a postdoc in my lab he's now a full professor of pen and joe was interested in one of these fundamental weird intransitivities this uh which is called impulsivity in discounting when we make choices in time if i let me put it this way if i say to arrow arrow who's one of the most patient people i know i mean disturbingly so and i say era which would you rather have 20 now or 22 in a month i'm hoping that arrow would say i would rather have 20 now it's not worth waiting 30 days for two dollars a perfectly reasonable statement can you live with that but if i ask arrow okay in you know hang on hang on we'll flip a coin in a minute um if i say to arrow yeah you're right that's fair okay okay okay no there's more coming it said but if i said to arrow in in a year 20 or in 13 months 22 dollars if air is normal he'll say well it's a year from now i'll take the 22 away the extra month now i want you to understand this is an intransitive decision because as we're marching through time every day i said arrow well you said you'll take 20 now but you'll take 22 dollars if you have if it's a year in the future i ask him again after a month i ask him again after a month after you get that at some point i walk up to him and i say oh it's uh been 263 days you're gonna stick with your old decision he says no i'm changing my mind and then he gives me back the twenty dollars so okay so people do this it's a really weird behavior economists struggle with understanding why they do it it's called hyperbolic discounting in our trade and so all we did was we said oh well that's got to be because there's an impulsive little guy in the brain and when money is immediately available he says i'll take it i'll take it but there's a patient guy somewhere else in the brain and when it's so far off in the future that patient guy controls behavior and we ought to be able to design an experiment we can find the impulsive guy and the patient guy and uh separate them biologically i actually thought that experiment would probably work as some of you know john cohen's lab did a very fast version of that experiment and seemed to find evidence for the uh in the let's see for he he found evidence for the patient guy no the impulsive guy i can't remember which one he said he found um he found evidence for the impulsive guy but not the patient guy and he said the patient got somewhere else i don't know so what joe did was i think really put this to bed in a long series of papers that really made his name this is an example of a really patient a moderately patient chooser woodford's here so this is not a very patient chooser he knows what a real patient user looks like because he's a real economist and what i'm showing you is how the value of money declines with delay up to 180 days and you can see the money drops here loses about 40 of its value for this chooser this is a really crazy impulsive chooser this guy money loses in six months 98 percent of its value and what joe showed was that regardless of whether you're a steep discounter a medium discounter or a super steep discounter there's always basically two places in your brain where you can see the value of money at whatever delay you're going to get it and that's the medial prefrontal cortex and the ventral striatum and it turns out this is a really universal phenomenon i can read out the activity in this brain area look at how it declines for a chooser with delay this is shown in black for the neurobiological data and in red is the behavioral measurement so there's this perfect perfect match between the activity at this one spot and your willingness to wait if you're impulsive this spot is impulsive if you're patient the spot is patient and there's no evidence that there are two people in you there's just one and it has this weird hyperbolic discounting function which is hard to understand and which is intransitive everybody got it so you are intransitive that's absolutely true but it's not because there are two it doesn't seem to be two people you seem to be coherently intransitive now this turned out to be a widespread finding there have now been 20 labs that have demonstrated it it's been demonstrated in hundreds of papers there's kind of no doubt at left at this point your ventral medial prefrontal cortex and your ventral striatum are impulsive if you're impulsive they're patient if you're patient and they show this nice clean function there's one representation of value but it has this weird feature but maybe that's just about discounting when a fat levy joined my lab that's now a full professor yale she did a similar kind of experiment she looked at people facing risky options these are kind of traditional economic lottery choices versus uh lotteries where we'd obscured some of the probability people hate that and the story was oh well changes may be in your response to risk when you know what the risk is and when you don't that maybe represents two people there's kind of like an angry little squirrel somewhere in your head that's afraid and when we turn this thing on that afraid little squirrel engages and it leads to the changes that appear across these two cases and again if i did that experiment i'm not going to belabor it and the story was exactly the same the medial prefrontal cortex and the ventral striatum capture everything there's a single representation of value it's in this one place it probably comes from lots of different complicated inputs for sure i'm not telling you about any of that that's cool and interesting but somewhere in the brain there's this one value representation it predicts what you're going to do even when you're being intransitive i think the most compelling version of this was for by russ poldrack and craig fox a pair an economist and a neuroscientist and they looked at how you represent losses in the brain and how you represent gains in the brain surely being afraid of losses we treat losses really differently than gains it's really weird they saw the same thing if the brain area represents gains it represents losses losses are just negative gains there's no separate system for representing losses if anything the losses are represented less completely in the brain so this led us to propose um in about 2012 for the first time that there was a kind of a single common representation of value in the brain and that it was irrational and that there was no hint of these multiple critters living in your brain and this is uh this original proposal was by dino levy another of my postdocs who's now full professor at the university of tel aviv and dino here dino showing a social experiment this is a representation of value when you're valuing time with another person who you'd like to be with or valuing getting away from somebody you don't like being with monetary values and there's you can see really clearly that these are all represented in the same place the story's so clean joe cable then went and redid this experiment he did a 250 study meta-analysis showed the same thing antonio rangel's group at caltech did this experiment again and he showed the same thing with john clitherow okay so i'm just telling you you better believe me there's one there is a common value representation in the brain there are not a lot of people in your head there's one of you in your head but that one of you is weird so why is that one of you so darn weird now psychophysicists thought about this problem for a long time and economists have two um you know if if i was a if i was a neo-classical economist from the 1950s my idea would be that there's a bunch of cool stuff out there here's something of low value it's a little candy here's a cool sports car and these things are transformed by some compressive function into what you might think of as the subjective value you place on these things and when you make choices says that economist i just say which would i have a candy well that's worth about you know one util or this cool sports car that's worth like a gazillion noodles and if i give arrow a choice would you have a candy or the sports car hopefully arrow says give me the sports car everybody good now psychophysicists have thought about this kind of same idea psychophysicists have a slightly different take on it which then began into influence economics really strongly in the 1970s and that's the notion that these transforms from objective to subjective have an intrinsic variance term the idea is that if i tell you the objective value of something you don't get a particular number out you get some range of numbers out which has some noise distribution around it this was a classical idea this is the just noticeable difference of psychophysics from the 1800s it entered economics through the work of dan mcfadden in the mid 1970s so that's all kind of interesting and i want you to now bear in mind this is the central thing i'm going to talk about today that our representations are noisy and that is a fundamental problem in everything about our neural architecture everything strange you do is about solving that problem let me flesh that out because we don't often think about it this way i want i want you to understand how big a problem this is our brains consume about 10 watts of power the crappy computer on my desktop consumes about 800 watts a good postdoc in my lab has a computer that consumes a couple of thousand watts it's tempting to say that's because this is such a bad machine but that's just not true anymore that might have been true 30 years ago this machine can do a lot it's super precise but it's using about 30 times as much power as we are 40 times as much power as we are so that's interesting we're operating in a very low power regime that's a fundamental feature of biological organisms i eat well i'm not going to tell you how much i eat aero eats 2 000 kilocalories a day of which 400 go to serve his brain now let's imagine that arrow decided he wanted just i'm not going to show that picture don't worry that he wanted to just increase his precision neural precision by a factor of 10. that's just one decimal place what would that involve that would involve something like scaling up the size of arrow's head ten times now you know which picture i'm thinking of a 10-time scale up of arrow's brain to 100 watt brain his his brain would now consume 70 of his food he'd have to eat 4 000 calories just to feed his brain he would have to eat about 6 000 calories a day so arrow would have to eat three times as much food as he eats today to achieve one decimal place of increased precision everybody get this idea now think about that that means that aero would be much better at picking his favorite candy bar but he would have to eat three candy bars not one every time he made that choice and i don't think it's a stretch to say that sounds uneconomical okay i'm going to restate that from a paper that i published with my postdoc chi steverson and my longtime collaborator game theorist economist and uh thermodynamicist he actually is adam branenburger and i got to remind you that information and energy are the same thing everybody kind of knows this but remember that's a when we say that we can use information theory which derives from thermodynamics to explain the information and entropy of some concept we're not that's not an as if that's like really true right you can cool a computer chip by using information theory okay so what adam did was with after me nagging him for a long time was we just wrote down a standard thermodynamic equation from classic thermodynamics we wrote it down in information theoretic terms we asked what's the entropy of a given representation this could be anything it could be a car but i'm just using it about your brain but this is the laws of physics i'm not saying anything that interesting this entropy is simply the uh described by this little choice here let me i should have said it to left to right uh right to left as the probability of producing the right choice drops to chance the entropy of your representation goes up that's kind of dopey right that's like so easy now if you do enough magic math on this because i just actually mean a proof that is way outside my skill set we can rewrite that this way and what adam does here is he puts on the left all of the costs associated with reducing entropy so i'm going to improve my representation to make it more accurate and less entropic but i have to pay a cost and i'm going to put all the costs on the left-hand side and here i'm just taking the maximum possible entropy that's a system that is completely disorganized and produces no coherent behavior this is the entropy associated with some arbitrary neural encoding the difference is the entropy reduction that's been achieved and that has to be that improvement has to be multiplied by the cost of improving that's kind of obvious right so the interesting thing about this is that this relationship is multiplicative it seems almost trivial that it's multiplicative but you're going to see that's a really deep insight it's going to mean that all efficient representations are divisive by definition by thermodynamic constraint okay let me say that a slightly different way i'm just going to resave that here's a psychophysical curve which has high variance around it and you pay 10 watts for it if you want to reduce this variance you have to pay more in watts i just said that that's kind of trivial and the relationship's multiplicative everybody okay okay love loss there's arrow on the right and me on the left and that's probably not right okay um i should have thought of that before i said it okay so so now i'm going to take you the next step so the first thing i said was just thermodynamic law improve precision you got to pay for it so now let's take a look at how you would improve precision given that precision is really costly everybody okay here's the simplest possible way to represent value in the brain it is what you would call an expected value representation as i increase the objective value of something let's say in dollars i increase it linearly think about what that would look like so if i had to choose between an object here and an object here that would mean i would be comparing these two values internally in my internal representation remember we talked about the entropy of internal representations that looks pretty easy okay wait but let's put noise in and now let's look at what that noise projects on the left hand side so here i'm choosing between these two this is the error distribution around the bottom one this is the error distribution around the top one and i hope what you can see is with just a little noise this problem is now just about insoluble i am no way going to find the better candy bar reliably with just a little bit of noise everybody okay so that's a cost and let's say i told you that we're going to make choices over things that all lived in this value range well that's kind of interesting because you are now wasting all of this coding space everybody good with that you're only using a very narrow range to tell you something and this is because i've told you that the choice that has this intrinsic correlational structure that's just the same as saying that there's a hidden loss if the choice sets are structured i'm going to speed up a tiny bit what i really should do is adjust my coding function so now we're back to the neural representation right that i was telling you you have to adjust your neural representation to minimize entropy i should adjust my function so that it shows all of its dynamic range where i'm expecting to encounter my choice objects this is so obvious and in fact that's just that's the trick here i'm doing this more formally this is really work that harkens too this is multi-dimensional and it's much harder but this is kind of simon laflin said this in the 70s and his idea was you take the distribution the probabilistic distribution of the things you're going to have to face he was talking about visual stimuli we're talking about choice objects and you simply take its integral said laughlin and this integral which is now going to look pretty sigmoidal that's going to be the most efficient representation if you face noise let me show you that in tiny bit more detail see here's if you don't use the sigmoid and i've got this huge amount of overlap and here i've used the sigmoid and centered it on my two choice objects and you can see how much i've driven the two representations apart okay so sigmoids are a signature of respecting the losses they're that little f function okay so i'm saying that a slightly different way i'm saying that what you really want to do in order to maximize information in the posterior distribution is you take the thing you're looking at true value and you divide it by all the costs all the losses all the bad stuff goes into the denominator this is a really deep fact if you tell me that the representation you're using is subtractive as many choice representations are this tells me that that's not efficient provably not efficient only divisively normalized functions can efficiently incorporate costs by the laws of thermodynamics this is sort of the core insight of that paper oh and i just said that okay so has anyone ever done that actually someone in this room did that but um less arrow and heater and i start fighting with each other luckily heger's not here so we don't have to um he republished it first that's definitely true and so heger's idea and this should really be familiar was that there's probably something really good and efficient about building a visual coding system in which the input to the visual system is divided by the activity of all of its neighbor cells so david's idea when he said that was um that the denominator would carry something like well something about the variance of this inputs and some kind of weighted sum of all of the inputs and that what would at the time we all thought we were doing was we were capturing information that was shared amongst all the units nearby and sort of dividing it out of the representation to maximize information in the output everybody okay with this idea this is pretty familiar arrow really did the math on this um i'm just going to share the intuition really fast looking again at my hero john von neumann arrow would have said it i think this way but not with a picture but with a picture of some like 1960s lady from bell labs and so i'm going to look at the pixels on his forehead if um pixels are correlated and they're near each other this is the fact of life if i know this pixel is black sorry if i know all these outer pixels are black then i know this inner pixel is black with a probability of like 99.9 percent and we want to just kind of incorporate that into our models okay so now i'm going to say the same thing another way i know this is boring i keep saying the same thing this is arrow and this is arrows emmy in case you didn't know okay it the error looked like that when i met him okay so the idea here is what arrow did with adelia schwartz and with martin lanewright which was super interesting was they were kind of chasing the same thread numerically not in a closed form proof and they examined what happens to the information content to the entropy numerically of the output when you looked at 50 000 i think 50 000 pictures and so they would show this this encoding scheme 50 000 images and they would tune this number and this number and this number empirically and see if they could gradient descent to really high efficiency representations and they found that there was a appeared to be a strong local minima and that you could actually show that this encoding scheme seemed to really give you a superbly efficient representation of images and if you follow this thread long enough you can when it you too can win an emmy for encoding audio images audio sound sounds whatever audio stuff okay so now i'm just going to repeat this paper i know i wasted a huge amount of time but this is the core insight and it's going to go really fast after this there are constraints in the outside world about how entropy works and the most important constraint is that if you want to decrease entropy increase information do a better job get more rewards you have to pay more in terms of energy now when we organize that equation we can actually put all the costs or losses kind of in one space of the equation and on the other we can put the thing we're trying to keep track of when we do that the thing we're keeping track of always goes into the numerator and the thing that we're trying the costs and losses always go into the denominator and the denominators generally have to have a constant in them and another piece which we're going to look at but remember that's the equation that arrow and david had kind of pioneered this equation called divisive normalization so now what i'm telling you is divisive normalization is provably a member of a class that is efficient for representing value and that if you use this class you ought to be able to explain a lot of stuff everybody okay at this point now i'm going to add one last fact before we go into all the cool stuff and that is we were also able to prove that this divisive normalization style representation is actually equivalent to the loose choice rule with a little tweak that allows the loose choice rule to be a little bit irrational and that's kind of cool because it meant that we had proven identity between the laws of thermodynamics something pretty darn close to arrows divisive normalization and the violations of choice theory that we've been trying to study for the preceding 20 years okay so i said all that i said all that i said all that so how does this really work okay so now i'm going to now chase this equation for a while i'm going to argue that the left side of this equation is how much something is subjectively worth to me like utility or subjective value or discounted value or whatever you want it to be and that the discounted the utility is simply the true value of the object raised to an exponent over what's going to turn out to be the mean value of the choice set the center where i want that function to twist plus the sum of all the things i'm looking at and considering as my current choice set raised to this exponent okay let me flesh that out now let's take a look at what beta does changing this exponent when beta is small the curve looks kind of like this and as beta increases the steepness of the curve goes up this look should look really familiar to you this is a neoclassical utility function it's exactly what von neumann drew it's what bernoulli drew in 1750. this is carmen traversky's value function the puzzling irrationality that arises sometimes and what i'm telling you is that divisively normalized equations have one continuous property which is they can switch from whether it's two continuous properties through the other one in a second they can switch from this neoclassical utility function to this steeper uh conor mctraverski style utility function so this core rationality why does it arise it arises because we're dealing with noise the efficient solution to noise is to build an internal representation which can sweep from the neoclassical function to the most arbitrary condiment risky style function you can imagine it'll be okay now there's the second term in heger's original equation this was a sigma and what it does is it causes the function to shift to the right what it actually does is it controls the center point of the function everybody see that and so that's kind of cool because remember i showed you in that earlier picture that at least theoretically what you'd want to do is center the distrib the curve on the center of your distribution and then you'd want to adjust its slope maybe i'm going to show you why you want to do that in a second okay everybody good with this idea so now i'm just like no i didn't just show you um a standard behavioral economic set of functions i showed you a set of physical laws derived from thermodynamics they just happen to look just like behavioral economics okay so that's a cool story at this is the point at which any experimentalists should say paul that was a great story and i really couldn't care less because you told me something neat about thermodynamics but you didn't tell me anything about the brain like you're sitting there going like oh my god another theory talk okay so the first time we went after this was really simple this was with um my long-term collaborator uh kenway louis who's at nyu and kenway and i were recording from single neurons that we hypothesized encoded a value signal based on some earlier experiments and what we did is we just had monkeys choosing between a green target and a red target and the only trick was we would vary the magnitude of reward for the green target or the magnitude of a reward for the red target not that interesting the monkey just has to find the better target sometimes we'll be recording from a neuron telling us about the green target and sometimes we'll be recording from a neuron telling us about the red target okay this is not so great it's like so what so here on this bottom row i wonder why it's doing that here on this bottom row what i'm going to do is i'm going to increase the value of the target in the response field and you can see the neuronal firing rate goes up okay so that's good we already shown that the firing rates code something about the target everybody good with that but here's the kind of interesting thing the denominator of this equation says something weird the thermodynamics tell us that if i increase the value of the target in the response field firing rate should go up but if i increase the value of sorry in the response field the firing rate should go up if i increase the value out of the response field i increase the size of the denominator and the firing rate should go down everybody got it and sure enough when we increase the target outside the responsibility this totally unexpected property appears the fairing rate goes down okay that's kind of meh how about this because growing growing the denominator this sensitized us to the importance of the denominator imagine i was looking at a normal value system so what i'm drawing is along the horizontal axis is the firing rate of my neurons and it's in response to a stimulus with an offer which has some mean value at the center of this gaussian so i get some sort of like noise distribution every time i show my monkey this little target i got a firing rate that's drawn from this gaussian and there are two options one here and one here and what i want you to see is the blue ones better than the black one that but they kind of overlap a little so this monkey gets it wrong about 20 of the time everybody good so here's this crazy thing about the about the normalization about the thermodynamics as i increase the value of a third option that the monkey will never ever ever ever ever pick but the monkey knows it's there and he knows what his value is so he's representing it in his choice set these guys decrease in their firing rate because the denominator is growing i'm imposing an informational constraint i'm increasing the entropy of the system by shifting that thing to the left everybody got it and so the prediction is that an unchosen third target as it increases in value should increase the stochasticity of the monkey in choosing amongst these two targets this is a really weird prediction so we did that we trained monkeys to make choices they're choosing between a fixed option and an option that's increasing in value you can imagine here the monkey's indifferent here he weakly prefers this one here he strongly prefers this one i'm going to do it under two conditions once when the third target is really really crappy and once when the third target is only pretty crappy and here's what that data looks like here we're looking at two monkeys this is what happens when the distractor is small and what i want you to see is the monkey this if you don't look at choice curves all day like me this choice curve may be a little uh weird here he's at 50 50. he doesn't care they're the same here he's getting right about 80 of the time everybody got that when we move the unchosen third target up in value he goes from getting it right 80 percent of the time to getting it right only 65 percent of the time this is a huge impact of an unchosen target but you know it makes perfect sense from an information theoretical point of view i'm injecting more entropy into the system the system has to fix informational capacity the degradation is predicted by that equation i showed you which captures this basic idea he never chooses it so you might say aero might say well how does he even know what's there and the answer is every what we actually make him do is we make him take the third target every five trials the lights flash and say to him on this trailer you have to sample the unwanted third target you can choose during the other trials whatever you want and so we can actually say with absolute certainty once they once they were trained properly which took a few weeks um they never once took the crappy target under any circumstance except when we told them they had to and we of course we had to tell them to take it once in a while because we were moving around its value every day and so it would go from low to high high to low low to high high to low so they had to be forced to sample to know what block they were in and as soon as they sampled it firing rates the global firing rates start dropping and the efficiency of the choice goes to pieces and this is true of humans too as soon as we did this people were like monkeys so here's the drop this is the slope of the logistic here's the logistic changing slope i'm not going to belabor this this is the logistic slope dropping the choice curve flattening as the offer as a third option a distracting option increases in value climbing up this little hill so humans show the same behavior and these are really robust the two things i told you have been seen now in like 10 labs 20 labs they're completely uncontroversial here's another one this is i mean it's crazy than all this work i have to say this is the called the curse of choice this is a kind of well-known fact if i give you too many options to choose amongst you do a really really bad job now of course you can imagine what i'm thinking is as i'm adding options to the choice set i'm increasing the informational burden on the network and that's increasing the denominator and the result is that the choice should go to pieces and should go to pieces in a very particular way a way predicted by this divisive relationship not by a subtractive relationship not by a multinomial probe relationship not by any of that stuff and so um this is work that i did with kenway uh with and with ryan webb another former postdoc who's now uh an associate professor at the university of toronto and here's like a cartoon of this the the full the really beautiful version of this paper just came out two years ago in management science what i'm showing you here is the probability that you'll pick the best item as a function of how many items i put in front of you the data is actually this red line so if it's two you get it right about i pick things that are hard you get it right only about 68 of the time but if there are 12 you basically you really suck at this here's the probability you'll pick the second ranked item 32 percent if there are only two spinning down to whatever it is okay and here's the third and here's this captured for up to 12. and what i want you to see is um this blue line is a divisive model and the green line is a multinomial probate it's the standard economic model now i'm trying to fit all the choices with one model so that makes it a hard problem because there's tons and tons of data i have to fit with just two free parameters and um this really looks like a divisive normalization story okay i'm telling you one more i promise this is the last one i think it's the last one and this now has also been replicated in my old postdoc ignacio temulos lab at the university of sydney using a totally different procedure but the idea is really simple in the equation sorry i have to go back to the equation i thought i had it in that slide help where's my little precious equation uh this little guy here right he controls the left right position of this function right everybody got this so here's a kind of mean trick imagine i made arrow choose over really really crappy things for a while and so his b got really really small he shifted his function way off to the left and then without warning i suddenly changed to high value options his function would take a little while to recalibrate i'll show you that in a second and the prediction is that he'd be making his choices up in the raw up at this place where first off he'd be really noisy and second off oddly he'd be over bidding he'd see things as higher value than they really are this is kind of weird this is a really weird irrationality i think so mel cod did this mel it was a graduate of mine who actually now uh works for a major video game company he works for xbox he's the smartest of us all right um and so in mel's experiment what we're looking at um are 30 goods ranked from the crummiest to the best and we use a procedure to figure out this is subject-specific ranking we know exactly what they're worth in dollars each one of them and this is trial number so at first mel just starts throwing things up hey here's the snickers bar how much do you want for that snicker how much would you pay to eat that snickers bar there's a lot of subtlety here the subtlety is the subjects are starving it's trapped in the lab and they can only eat the food that they buy and um there's a fixed probability on each trial that will stop the game and throw a die and then they'll they'll either buy the food or not buy the food using an incentive compatible mechanism called the beggar to group mark shack auction and i'm not telling you about that just trust me we know we know what this thing's worth to them okay so they tell us and we actually also ask how much do you love it okay we do that for like 80 trials and then we pick all of the high valued options and we make them bid on them for 300 trials and then we go back and we check the whole set and then we have them bid on low ones and we check the whole set so i'm going to show you the low adaptation i guess i have both yeah i do have both so here's what happens immediately after a high adaptation period the choosers a high adaptation period i told the story about a low but let's start with high the choosers under bid by 12 cents for these one dollar items that's a huge underbid and this underbid decays over the course of 90 trials about five minutes to here it takes about eight to ten minutes for them to get back to their baseline levels and if we low adapt them we do the same thing the black lines are the model fit the um the dots are obviously the data okay so this this works right um the story looks like divisive normalization is a pretty darn good predictor of what's going on in the brain and and i for me as a biologist that's really satisfying the idea here is that animals are shoved up against the thermodynamic problem they're trying to do the best they can with a noisy internal representation and it's not like we're bad animals it's just that representations are noisy in the brain and you're stuck with that and evolution knows this thermodynamic problem and it adopts the efficient solution which is a solution of this class everybody okay so far yeah so the way yeah that's a great that's a great question i i definitely cut that corner so this guy right everybody gets is trying to represent the middle of the distribution everybody got that it controls the left right position of the function so here's a really great question how do you know what the middle of the anticipated distribution is how do you do that especially if the distribution is not stationary like arrows sitting here i'm offering him 20 bills and candy and he has to go out in 10 minutes and buy his new maserati with his emmy award winnings and so now he's going to be in a much much higher value regime and he doesn't want to be using his candy bar function in the maserati shop everybody okay with that so there's a hidden piece here which is this is kind of the steady state equation how does the equation work dynamically now i'm not telling any of that story um like xj knows that we've been working on that problem with neural network models for about 10 years and we have a model that can compute this in real time and it uses pv positive interneurons and somatostatin interneurons and blah blah blah blah blah i'm not talking about any of that today so that's a really really good question and one that we've dug on really hard i think the idea you should just capture in your head is imagine that this was doing something like what a dopamine neuron does when it computes a reward prediction that's kind of the basic idea and the time constant is going to be super important has to be adjustable so think uh xj's bernanke papers where you might have a row of these mechanisms each operating with different time constants and you're going to have to select the one that's the right type constant think josh gold's lab and we've done a lot of work on that which i'm not just not i don't have any time to talk about okay so the next thing i want to say is uh we're really in the home stretch now the next thing i want to say is um one thing i have not really proven is that this particular equation that arrow and david and i have been monkeying around with on and off for the last 25 years is the optima i did not say that right everybody gets this what i said was it has to be divisive if anybody tells you it's subtractive they're itching for a fight the second thing i told you is it has to carry it has to have all the costs bundled into it and for distributions of choices that shift left and right to high value and low value it probably needs to have something that can shift it left and right and for distributions of choices that can flatten or peak i'm introducing a new idea here secretly it probably needs to adjust its peakiness and for distributions where the objects have different degrees of correlation it probably has to mess around with that too oh okay so this is the new idea the last new idea and this is an idea of uh my ex-graduate student stefan bucher who's sitting there quietly in the audience now mortified who is now a postdoc with peter diane and what stefan realized was that the optima can only be the optima for a particular choice environment imagine that the function is operating in a choice environment that has a very high average value and only three options there might be one solution one optimal encoding function for that and if you were in some other regime there might be some different optimal encoding function ah so this is an incredible idea of stefan's the idea that the optimal function depends on the probabilistic distribution of the input of the choice sets you face so this allows stephon to ask a really cool question that i could never have like i do not have anything like the skill set to ask which is okay rather than ask what the optima is we can ask the question backwards if paul and arrow and david have been obsessing with this equation for the last 35 years stefan asks can i push the equation backwards and ask what input distribution is it for which that particular function is information maximizing in the posterior oh it's such a good idea he's so smart so here's um so we start with the idea that the output distribution this is um this is just from my paper with um kai stevenson adam brandenburger we start with this idea that the output distribution has to be information maximizing i mean arrow really wrote about this fischer information maximizing whatever 10 years before i like even understood what he was talking about we have a transform function that's the divisive normalization equation and then we simply ask what's the input distribution everybody get this idea it's so simple and the answer is the divisive normalization equation is the optimal function for encoding a pareto type 3 distribution i'm sure you're relieved and delighted to learn this fact now i'm going to tell you about a little bit about prototype 3 distributions pareto type 3 distributions well obviously you get the idea that they can have a middle that can move back and forth captured by this parameter and this is kind of cool they have a steepness coefficient obviously captured by this parameter okay so now we suddenly understand what these two parameters do these two parameters with the constraint that we're going to live in a pareto type 3 world for a moment these two parameters allow the function to tune for the steepness of the distribution and its left right position that's why that that's the whole idea now it turns out that a pareto type 3 distribution is just a log logic to a first approximation so this is good news for yuri i started with this appalling representational story but i've managed to get to log normal distributions finally by the end of the duck but they have one other interesting feature which is you notice this thing is supposed to be pitched out a little bit it's a little hard to tell these two dimensions are correlated that is to say that the degree to which one offer tells us about the other offer is another variable that can be adjusted in this function and it actually uses this parameter right here i'm saying this bruce young who probably thinking that already okay so that's pretty cool are these distributions that anyone's interested in well it turns out that these are power law distributions really these are the pdfs of a family of these guys these are their cdfs and what i want you to notice is that this is kind of the one over f distribution to a very close first approximation so if you so arrow good news um as long as it's a log logic distribution you know like one over f distribution we have actually been studying the right function it is the optimal encoding scheme now okay so now now i've got to this really interesting kind of turning point in the talk so the story i've been telling you up till now is geez behavioral economics that story was that we're tragically busted because we don't follow neoclassical law in economics because our choices are weird and what i'm telling you is oh you know what my hero john von neumann got wrong my hero john von neumann assumed that we were costless that we faced no costs when it came to representational precision and if he had understood that that representation of the brain is noisy and that there are thermodynamic costs imposed he would have figured all of this out in like an afternoon on a napkin and left it for some a poor economist to just publish for the next 10 years okay so it's all about the cost so that's cool but i've gone a step further and i've kind of hinted that this divisive normalization equation is the right equation for the world we live in and now i've kind of revealed to you that that's not exactly right divisive normalization equation is right only for this world and so this raises a really interesting possibility there are two possibilities one is we are actually perfectly efficient encoders and because aero and david and i have been so dumb as to always study these kinds of worlds we look like divisive normalization choosers everybody got this idea this is a really subtle point divisive normalization is optimal for a pareto type 3 world if humans were perfect encoders of whatever distributions they found they'd look like divisive normalizations and prototype normalizers and pareto type 3 worlds but they wouldn't look like that in some other worlds they'd look like other things this is a really cool idea so i'm going to ask the question in this last bit and i'm going to show you an experiment that's not really done but that is like the most exciting experiment in my career um is divisive normalization a feature the nervous system or is it an artifact of the fact that we've been studying choice distributions that look like this it's a really easy hypothesis to test now that i kind of get it and so what we're going to do is we're going to create um four worlds for a bunch of human choosers we're going to create a pareto world where they're going to be choosing over pareto distributed choice sets um michael what i really mean is a pareto distributed prize space from which i'm going to draw a choice set of either two items or six items or a uniform world where there's no correlational structure these are like arrows clouds from the a long time ago okay everybody got it so i'm gonna have uh pareto uniform two item and six item i have very clear predictions about what a pareto person's to do and it's going to work the pareto person is going to do fine the question is going to be what happens when i ask these people to look at uniform distributions are they still going to normalize everybody got that idea because they shouldn't in a uniform distribution they should just be linear encoders let's look at the trick if you're really following all of this i'm sure woodford's thinking this so i could have said so he doesn't think i didn't notice it in the two item and the six item case of course it's not linear it's a rising function and um the six one rises pretty fast which was the whole point so the if you think about it michael the six one should induce risk seeking in a perfect encoder okay so it's simple blah blah blah what we're going to do is uh we're going to either draw from a uniform distribution two lotteries and you're going to tell me which one you want and they're always going to be drawn to from a uniform distribution and they're going to do 400 trials of this and then we're going to use a pareto with a covariance term and we're it is so hard to do this in real time the sampling is like nightmarish and then they're going to tell us which of these they like and we're going to do it either with two options or with six options here's what the six option one looks like it's really hard by the way um oh and i got the wrong one here this was supposed to be the pareto one this is the work of my two post docs uh bird kurtz and uh vinnie elatti vinnie is an economist and varied is a an economist neuroscientist just kind of really both okay so i'm going to show you one last thing and it's a so this is really preliminary so don't believe anything i tell you what this is a sort of econometric way to do it what we basically do is we fit all the data with the divisive normalization equation but we put this little multiplier out here omega and we just ask is omega bigger than one bigger than zero no yeah bigger than zero if omega is bigger than 0 see i have a little constant here that's my noise term if omega is bigger than 0 this is telling me that their choices are sigmoidal it's a little obscure but does everybody kind of get this idea if this lower term is significant they're doing divisive optimization and if this lower term isn't significant they're not and so i'm going to look at that in the pareto 2 in the uniform 2 in the pareto five and in the uniform five and here's the test this little guy and this little guy are super duper pretty significant okay so let me say that another way at least in this preliminary data set what i'm telling you is people are obligate divisive normalizers even when it's inefficient okay that is a super deep fact because i have now come full circle i started with conor mcbriskey telling us that we were really inefficient and then i told you this whole great efficiency story which turns out to only be true in a pareto type 3 world and it turns out it looks like we evolved for something like a pareto type 3 world or something close to it and when we get moved out of that world we still use a pareto type 3 model so it turns out that in a way everybody was right the neumann was kind of right that were sharp efficient choosers tavisky we're right that we face biological constraints but it's not the constraint that they expected we're constrained in the models we can use to build our representations it looks like we're constrained to these thermodynamically efficient divisive models which fail actually only in iia worlds which are pretty probably rare in the real world so that's kind of cool okay so i'm bringing the training to the station i just want to say this one more way which is really kind of puzzling and weird and i'm prompted to say this because woodford's here why are people risk-averse why are people risk-averse the standard story from the 1700s is people are risk averse because it makes sense people don't try and maximize their average long-run value they try and maximize some transform of average long-run value called utility and that's why people are risk-averse that's the story and i'm telling you that the curvature of the utility function which induces risk aversion is actually an optimal solution adopted by a noisy machine to maximize long-run value okay so what i'm really saying is pascal was right to a first approximation or i'm hinting that pascal may have been right pascal when he was the first choice theorist in the west he said people just maximize average longer in value people don't do that even bernoulli saw that by 1750 it was clear that they don't and so they invented risk aversion and by 1965 it was clear that they screwed up probabilities and by 1980 it was clear that there were hyperbolic discounters and by and all these things accumulate the first of them is bernoulli's and the answer is we were going down a blind alley the whole time we were being efficient and we were maximizing expected value and all this stuff just comes out of thermodynamics okay thank you that's my story [Applause] [Music] you