al limits that we had in a world of CPUs and sequential processing. And we've 
unlocked not only a new way to do computing and and but also a way to continue to improve. Parallel 
processing has a a different kind of physics to it than the improvements that we were able to make 
on CPUs. I'm curious, what are the scientific or technological limitations that we face now in 
the current world that you're thinking a lot about? Well everything in the end is about how much 
work you can get done within the limitations of the energy that you have. And so that's 
a physical limit and the laws of physics about transporting information and 
transporting bits, flipping bits and transporting bits, at the end of the day the energy it takes 
to do that limits what we can get done. And the amount of energy that we have limits what we can 
get done. We're far from having any fundamental limits that keep us from advancing. In the meantime, 
we seek to build better and more energy efficient computers. This little computer, the the 
big version of it was $250,000 - Pick up? - Yeah Yeah that's little baby DIGITS yeah. This is 
an AI supercomputer. The version that I delivered, this is just a prototype so it's a mockup.
The very first version was DGX 1, I delivered to Open AI in 2016 and that was $250,000. 
10,000 times more power, more energy necessary than this version and this version has six times 
more performance. I know, it's incredible. We're in a whole in the world. And it's only since 2016 
and so eight years later we've in increased the energy efficiency of computing by 10,000 times. 
And imagine if we became 10,000 times more energy efficient or if a car was 10,000 times more 
energy efficient or electric light bulb was 10,000 times more energy efficient. Our light 
bulb would be right now instead of 100 Watts, 10,000 times less producing the same illumination. 
Yeah and so the energy efficiency of computing particularly for AI computing that we've 
been working on has adva
-> summary ->
*   The transition to parallel processing represents a distinct shift from CPU-based improvements, fundamentally altering computational possibilities.
*   Current technological limitations are primarily dictated by the energy constraints associated with information transport and bit manipulation within physical laws.
*   Significant advancements in AI computing, specifically focusing on energy efficiency, have occurred since 2016, demonstrating a 10,000-fold increase in efficiency compared to earlier systems like the DGX 1.
*   The pursuit of greater energy efficiency in computing, particularly for artificial intelligence, remains a key area of development, with potential implications comparable to dramatic improvements in conventional technologies.