uman, it could be it could do an incredibly good job pretending to be a specific human. And so
the spectrum of areas we have to be concerned about is fairly clear and 
there's a lot of people who are working on it. There's a some of the stuff, 
some of the stuff related to AI safety requires deep research and deep engineering and 
that's simply, it wants to do the right thing it just didn't perform it right and as a result hurt 
somebody. You know for example self-driving car that wants to drive nicely and drive properly 
and just somehow the sensor broke down or it didn't detect something. Or you know made it 
too aggressive turn or whatever it is. It did it poorly. It did it wrongly. And so that's
a whole bunch of engineering that has to be done to to make sure that AI safety is upheld 
by making sure that the product functions properly. And then and then lastly you know whatever what 
happens if the system, the AI wants to do a good job but the system failed. Meaning the AI wanted 
to stop something from happening and it turned out just when it wanted to do 
it, the machine broke down. And so this is no different than a flight computer inside 
a plane having three versions of them and then so there's triple redundancy inside the 
system inside autopilots and then you have two pilots and then you have air traffic control 
and then you have other pilots watching out for these pilots. And so that the AI safety 
systems has to be architected as a community such that such that these AIs one, work,
function properly. When they don't function properly, they don't put people in harm's 
way. And that they're sufficient safety and security systems all around them to make sure 
that we keep AI safe. And so there's this spectrum of conversation is gigantic and and 
you know we have to take the parts, take the parts apart and and build them as engineers. One 
of the incredible things about this moment that we're in right now is that we no longer have a 
lot of the technologic
-> summary ->
*   Significant research and specialized engineering are required to ensure artificial intelligence systems operate reliably and avoid unintended consequences.
*   A primary concern involves instances where AI systems, intending to perform correctly, experience functional failures resulting in potential harm.
*   AI safety architecture necessitates a layered, community-based approach, incorporating redundancy and external oversight to mitigate risks associated with system malfunctions.
*   The complexity of AI safety demands a vast, multifaceted conversation, requiring deliberate engineering efforts to establish robust safeguards and operational protocols.