uman, it could be it could do an incredibly good job pretending to be a specific human. And so
the spectrum of areas we have to be concerned about is fairly clear and 
there's a lot of people who are working on it. There's a some of the stuff, 
some of the stuff related to AI safety requires deep research and deep engineering and 
that's simply, it wants to do the right thing it just didn't perform it right and as a result hurt 
somebody. You know for example self-driving car that wants to drive nicely and drive properly 
and just somehow the sensor broke down or it didn't detect something. Or you know made it 
too aggressive turn or whatever it is. It did it poorly. It did it wrongly. And so that's
a whole bunch of engineering that has to be done to to make sure that AI safety is upheld 
by making sure that the product functions properly. And then and then lastly you know whatever what 
happens if the system, the AI wants to do a good job but the system failed. Meaning the AI wanted 
to stop something from happening and it turned out just when it wanted to do 
it, the machine broke down. And so this is no different than a flight computer inside 
a plane having three versions of them and then so there's triple redundancy inside the 
system inside autopilots and then you have two pilots and then you have air traffic control 
and then you have other pilots watching out for these pilots. And so that the AI safety 
systems has to be architected as a community such that such that these AIs one, work,
function properly. When they don't function properly, they don't put people in harm's 
way. And that they're sufficient safety and security systems all around them to make sure 
that we keep AI safe. And so there's this spectrum of conversation is gigantic and and 
you know we have to take the parts, take the parts apart and and build them as engineers. One 
of the incredible things about this moment that we're in right now is that we no longer have a 
lot of the technologic
-> summary ->
*   The development of AI safety necessitates extensive research and sophisticated engineering to ensure systems function correctly and avoid unintended negative consequences.
*   A primary concern involves instances where AI systems, attempting to perform desired actions, experience malfunctions leading to potential harm.
*   AI safety architecture requires a layered approach, incorporating redundancy and diverse oversight mechanisms, analogous to those found in critical systems like aircraft autopilots.
*   The scope of AI safety considerations is expansive, demanding a comprehensive, collaborative engineering effort to establish robust safeguards and maintain system security.