. And in fac, in 2012 Ilya Sutskever, 
and Alex Krizhevsky and Geoff Hinton in the University of Toronto the lab that they were at they reached 
out to a gForce GTX 580 because they learned about CUDA and that CUDA might be able to to be used as 
a parallel processor for training AlexNet and so our inspiration that GeForce could be the the 
vehicle to bring out this parallel architecture into the world and that researchers would somehow 
find it someday was a good was a good strategy. It was a strategy based on hope, but it was also 
reasoned hope. The thing that really caught our attention was simultaneously we were trying 
to solve the computer vision problem inside the company and we were trying to get CUDA to 
be a good computer vision processor and we were frustrated by a whole bunch of early 
developments internally with respect to our computer vision effort and getting CUDA to be 
able to do it. And all of a sudden we saw AlexNet, this new algorithm that is completely 
different than computer vision algorithms before it, take a giant leap in terms of capability 
for computer vision. And when we saw that it was partly out of interest but partly because we were 
struggling with something ourselves. And so we were we were highly interested to want to see it work. 
And so when we when we looked at AlexNet we were inspired by that. But the big breakthrough I 
would say is when we when we saw AlexNet, we asked ourselves you know, how far can AlexNet 
go? If it can do this with computer vision, how far can it go? And if it if it could go to the 
limits of what we think it could go, the type of problems it could solve, what would it mean for 
the computer industry? And what would it mean for the computer architecture? And we were, 
we rightfully reasoned that if machine learning, if the deep learning architecture can scale, 
the vast majority of machine learning problems could be represented with deep neural networks. And 
the type of problems we could solve with mac
-> summary ->
*   Researchers at the University of Toronto leveraged the GeForce GTX 580’s CUDA capabilities, anticipating a parallel processing solution for training AlexNet.
*   Concurrent company efforts to develop CUDA for computer vision were hampered, creating a context for observing AlexNet’s unexpectedly advanced performance.
*   The emergence of AlexNet prompted an inquiry into its potential scalability, specifically concerning its applicability to broader machine learning challenges.
*   The observed success of AlexNet suggested a paradigm shift within the computer industry, positing that deep learning architectures could effectively address a significant proportion of machine learning problems.